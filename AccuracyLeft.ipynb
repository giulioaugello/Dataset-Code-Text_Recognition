{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import arange, mean, std\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "         AxMean     AxMed     AxStd     AxVar     AxMax     AxMin    AyMean  \\\n0      0.137554  0.064636  0.356773  0.127287  1.051056 -0.110138  2.961190   \n1      0.590167  0.679947  0.403956  0.163180  1.103729 -0.134079  2.469620   \n2      0.331192  0.325607  0.397967  0.158378  1.027115  0.009567  2.721668   \n3     -0.447721 -0.495605  0.349624  0.122237  0.090973 -0.988815  2.018710   \n4      0.395437  0.402222  0.179063  0.032064  0.622482  0.074219  1.259748   \n...         ...       ...       ...       ...       ...       ...       ...   \n16757  0.292690  0.304062  0.022743  0.000517  0.304062  0.258575  0.882263   \n16758 -0.699108 -0.713470  0.028725  0.000825 -0.656021 -0.713470  1.756138   \n16759 -1.127679 -1.065430  0.085239  0.007266 -1.065430 -1.221054  1.631400   \n16760  0.440536  0.440536  0.000000  0.000000  0.440536  0.440536  1.857895   \n16761  2.084554  2.202667  0.204578  0.041852  2.202667  1.848328  3.555389   \n\n          AyMed     AyStd     AyVar  ...  PreMean  PreMed  PreStd  PreVar  \\\n0      3.021484  0.322891  0.104259  ...      1.0     1.0     0.0     0.0   \n1      2.303223  0.459437  0.211083  ...      1.0     1.0     0.0     0.0   \n2      2.700653  0.293869  0.086359  ...      1.0     1.0     0.0     0.0   \n3      2.047043  0.283701  0.080486  ...      1.0     1.0     0.0     0.0   \n4      1.280899  0.191081  0.036512  ...      1.0     1.0     0.0     0.0   \n...         ...       ...       ...  ...      ...     ...     ...     ...   \n16757  0.871490  0.021545  0.000464  ...      1.0     1.0     0.0     0.0   \n16758  1.903381  0.294487  0.086723  ...      1.0     1.0     0.0     0.0   \n16759  1.620865  0.014425  0.000208  ...      1.0     1.0     0.0     0.0   \n16760  1.857895  0.000000  0.000000  ...      1.0     1.0     0.0     0.0   \n16761  3.971985  0.721565  0.520655  ...      1.0     1.0     0.0     0.0   \n\n       PreMax  PreMin  View    User  Hand  Smartphone  \n0         1.0     1.0     t  Chiara  LEFT    REALME 7  \n1         1.0     1.0     h  Chiara  LEFT    REALME 7  \n2         1.0     1.0     e  Chiara  LEFT    REALME 7  \n3         1.0     1.0        Chiara  LEFT    REALME 7  \n4         1.0     1.0     r  Chiara  LEFT    REALME 7  \n...       ...     ...   ...     ...   ...         ...  \n16757     1.0     1.0        Chiara  LEFT    REALME 7  \n16758     1.0     1.0     z  Chiara  LEFT    REALME 7  \n16759     1.0     1.0     a  Chiara  LEFT    REALME 7  \n16760     1.0     1.0     c  Chiara  LEFT    REALME 7  \n16761     1.0     1.0     k  Chiara  LEFT    REALME 7  \n\n[16762 rows x 280 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AxMean</th>\n      <th>AxMed</th>\n      <th>AxStd</th>\n      <th>AxVar</th>\n      <th>AxMax</th>\n      <th>AxMin</th>\n      <th>AyMean</th>\n      <th>AyMed</th>\n      <th>AyStd</th>\n      <th>AyVar</th>\n      <th>...</th>\n      <th>PreMean</th>\n      <th>PreMed</th>\n      <th>PreStd</th>\n      <th>PreVar</th>\n      <th>PreMax</th>\n      <th>PreMin</th>\n      <th>View</th>\n      <th>User</th>\n      <th>Hand</th>\n      <th>Smartphone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.137554</td>\n      <td>0.064636</td>\n      <td>0.356773</td>\n      <td>0.127287</td>\n      <td>1.051056</td>\n      <td>-0.110138</td>\n      <td>2.961190</td>\n      <td>3.021484</td>\n      <td>0.322891</td>\n      <td>0.104259</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>t</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.590167</td>\n      <td>0.679947</td>\n      <td>0.403956</td>\n      <td>0.163180</td>\n      <td>1.103729</td>\n      <td>-0.134079</td>\n      <td>2.469620</td>\n      <td>2.303223</td>\n      <td>0.459437</td>\n      <td>0.211083</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>h</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.331192</td>\n      <td>0.325607</td>\n      <td>0.397967</td>\n      <td>0.158378</td>\n      <td>1.027115</td>\n      <td>0.009567</td>\n      <td>2.721668</td>\n      <td>2.700653</td>\n      <td>0.293869</td>\n      <td>0.086359</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>e</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.447721</td>\n      <td>-0.495605</td>\n      <td>0.349624</td>\n      <td>0.122237</td>\n      <td>0.090973</td>\n      <td>-0.988815</td>\n      <td>2.018710</td>\n      <td>2.047043</td>\n      <td>0.283701</td>\n      <td>0.080486</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td></td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.395437</td>\n      <td>0.402222</td>\n      <td>0.179063</td>\n      <td>0.032064</td>\n      <td>0.622482</td>\n      <td>0.074219</td>\n      <td>1.259748</td>\n      <td>1.280899</td>\n      <td>0.191081</td>\n      <td>0.036512</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>r</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16757</th>\n      <td>0.292690</td>\n      <td>0.304062</td>\n      <td>0.022743</td>\n      <td>0.000517</td>\n      <td>0.304062</td>\n      <td>0.258575</td>\n      <td>0.882263</td>\n      <td>0.871490</td>\n      <td>0.021545</td>\n      <td>0.000464</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td></td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>16758</th>\n      <td>-0.699108</td>\n      <td>-0.713470</td>\n      <td>0.028725</td>\n      <td>0.000825</td>\n      <td>-0.656021</td>\n      <td>-0.713470</td>\n      <td>1.756138</td>\n      <td>1.903381</td>\n      <td>0.294487</td>\n      <td>0.086723</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>z</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>16759</th>\n      <td>-1.127679</td>\n      <td>-1.065430</td>\n      <td>0.085239</td>\n      <td>0.007266</td>\n      <td>-1.065430</td>\n      <td>-1.221054</td>\n      <td>1.631400</td>\n      <td>1.620865</td>\n      <td>0.014425</td>\n      <td>0.000208</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>a</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>16760</th>\n      <td>0.440536</td>\n      <td>0.440536</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.440536</td>\n      <td>0.440536</td>\n      <td>1.857895</td>\n      <td>1.857895</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>c</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>16761</th>\n      <td>2.084554</td>\n      <td>2.202667</td>\n      <td>0.204578</td>\n      <td>0.041852</td>\n      <td>2.202667</td>\n      <td>1.848328</td>\n      <td>3.555389</td>\n      <td>3.971985</td>\n      <td>0.721565</td>\n      <td>0.520655</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>k</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n  </tbody>\n</table>\n<p>16762 rows × 280 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import csv\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\giuli\\\\Desktop\\\\ds Left\\\\merged\\\\mergedFileLeft.csv\")\n",
    "df\n",
    "# print(df.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Normalization between -1 and 1\n",
    "df_norm = df.copy()\n",
    "\n",
    "notnorm = ['View','User', 'Hand', 'Smartphone']\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "\n",
    "for col in list(df_norm.columns):\n",
    "    if col in notnorm:\n",
    "        continue\n",
    "    x = df_norm[[col]].values.astype(float) # cast to float\n",
    "    x_scaled = min_max_scaler.fit_transform(x) # fit data and transform it\n",
    "    df_norm[[col]] = x_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "         AxMean     AxMed     AxStd     AxVar     AxMax     AxMin    AyMean  \\\n0     -0.132653 -0.147185 -0.603221 -0.921283  0.032926 -0.109151  0.273847   \n1     -0.021683 -0.003086 -0.550748 -0.899086  0.045203 -0.114663  0.140869   \n2     -0.085178 -0.086068 -0.557407 -0.902056  0.027346 -0.081589  0.209052   \n3     -0.276150 -0.278387 -0.611171 -0.924406 -0.190848 -0.311467  0.018891   \n4     -0.069426 -0.068126 -0.800858 -0.980171 -0.066965 -0.066703 -0.186420   \n...         ...       ...       ...       ...       ...       ...       ...   \n16757 -0.094617 -0.091114 -0.974706 -0.999680 -0.141182 -0.024254 -0.288535   \n16758 -0.337784 -0.329409 -0.968054 -0.999490 -0.364956 -0.248069 -0.052138   \n16759 -0.442860 -0.411833 -0.905203 -0.995507 -0.460381 -0.364941 -0.085882   \n16760 -0.058369 -0.059153 -1.000000 -1.000000 -0.109373  0.017642 -0.024612   \n16761  0.344708  0.353518 -0.772482 -0.974118  0.301341  0.341788  0.434587   \n\n          AyMed     AyStd     AyVar  ...  PreMean  PreMed  PreStd  PreVar  \\\n0      0.271777 -0.630290 -0.931657  ...     -1.0    -1.0    -1.0    -1.0   \n1      0.087105 -0.473945 -0.861633  ...     -1.0    -1.0    -1.0    -1.0   \n2      0.189288 -0.663520 -0.943391  ...     -1.0    -1.0    -1.0    -1.0   \n3      0.021238 -0.675163 -0.947240  ...     -1.0    -1.0    -1.0    -1.0   \n4     -0.175745 -0.781213 -0.976066  ...     -1.0    -1.0    -1.0    -1.0   \n...         ...       ...       ...  ...      ...     ...     ...     ...   \n16757 -0.281008 -0.975331 -0.999696  ...     -1.0    -1.0    -1.0    -1.0   \n16758 -0.015699 -0.662813 -0.943152  ...     -1.0    -1.0    -1.0    -1.0   \n16759 -0.088337 -0.983483 -0.999864  ...     -1.0    -1.0    -1.0    -1.0   \n16760 -0.027394 -1.000000 -1.000000  ...     -1.0    -1.0    -1.0    -1.0   \n16761  0.516161 -0.173809 -0.658705  ...     -1.0    -1.0    -1.0    -1.0   \n\n       PreMax  PreMin  View    User  Hand  Smartphone  \n0        -1.0    -1.0     t  Chiara  LEFT    REALME 7  \n1        -1.0    -1.0     h  Chiara  LEFT    REALME 7  \n2        -1.0    -1.0     e  Chiara  LEFT    REALME 7  \n3        -1.0    -1.0        Chiara  LEFT    REALME 7  \n4        -1.0    -1.0     r  Chiara  LEFT    REALME 7  \n...       ...     ...   ...     ...   ...         ...  \n16757    -1.0    -1.0        Chiara  LEFT    REALME 7  \n16758    -1.0    -1.0     z  Chiara  LEFT    REALME 7  \n16759    -1.0    -1.0     a  Chiara  LEFT    REALME 7  \n16760    -1.0    -1.0     c  Chiara  LEFT    REALME 7  \n16761    -1.0    -1.0     k  Chiara  LEFT    REALME 7  \n\n[16762 rows x 280 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AxMean</th>\n      <th>AxMed</th>\n      <th>AxStd</th>\n      <th>AxVar</th>\n      <th>AxMax</th>\n      <th>AxMin</th>\n      <th>AyMean</th>\n      <th>AyMed</th>\n      <th>AyStd</th>\n      <th>AyVar</th>\n      <th>...</th>\n      <th>PreMean</th>\n      <th>PreMed</th>\n      <th>PreStd</th>\n      <th>PreVar</th>\n      <th>PreMax</th>\n      <th>PreMin</th>\n      <th>View</th>\n      <th>User</th>\n      <th>Hand</th>\n      <th>Smartphone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.132653</td>\n      <td>-0.147185</td>\n      <td>-0.603221</td>\n      <td>-0.921283</td>\n      <td>0.032926</td>\n      <td>-0.109151</td>\n      <td>0.273847</td>\n      <td>0.271777</td>\n      <td>-0.630290</td>\n      <td>-0.931657</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>t</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.021683</td>\n      <td>-0.003086</td>\n      <td>-0.550748</td>\n      <td>-0.899086</td>\n      <td>0.045203</td>\n      <td>-0.114663</td>\n      <td>0.140869</td>\n      <td>0.087105</td>\n      <td>-0.473945</td>\n      <td>-0.861633</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>h</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.085178</td>\n      <td>-0.086068</td>\n      <td>-0.557407</td>\n      <td>-0.902056</td>\n      <td>0.027346</td>\n      <td>-0.081589</td>\n      <td>0.209052</td>\n      <td>0.189288</td>\n      <td>-0.663520</td>\n      <td>-0.943391</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>e</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.276150</td>\n      <td>-0.278387</td>\n      <td>-0.611171</td>\n      <td>-0.924406</td>\n      <td>-0.190848</td>\n      <td>-0.311467</td>\n      <td>0.018891</td>\n      <td>0.021238</td>\n      <td>-0.675163</td>\n      <td>-0.947240</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td></td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.069426</td>\n      <td>-0.068126</td>\n      <td>-0.800858</td>\n      <td>-0.980171</td>\n      <td>-0.066965</td>\n      <td>-0.066703</td>\n      <td>-0.186420</td>\n      <td>-0.175745</td>\n      <td>-0.781213</td>\n      <td>-0.976066</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>r</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16757</th>\n      <td>-0.094617</td>\n      <td>-0.091114</td>\n      <td>-0.974706</td>\n      <td>-0.999680</td>\n      <td>-0.141182</td>\n      <td>-0.024254</td>\n      <td>-0.288535</td>\n      <td>-0.281008</td>\n      <td>-0.975331</td>\n      <td>-0.999696</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td></td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>16758</th>\n      <td>-0.337784</td>\n      <td>-0.329409</td>\n      <td>-0.968054</td>\n      <td>-0.999490</td>\n      <td>-0.364956</td>\n      <td>-0.248069</td>\n      <td>-0.052138</td>\n      <td>-0.015699</td>\n      <td>-0.662813</td>\n      <td>-0.943152</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>z</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>16759</th>\n      <td>-0.442860</td>\n      <td>-0.411833</td>\n      <td>-0.905203</td>\n      <td>-0.995507</td>\n      <td>-0.460381</td>\n      <td>-0.364941</td>\n      <td>-0.085882</td>\n      <td>-0.088337</td>\n      <td>-0.983483</td>\n      <td>-0.999864</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>a</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>16760</th>\n      <td>-0.058369</td>\n      <td>-0.059153</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.109373</td>\n      <td>0.017642</td>\n      <td>-0.024612</td>\n      <td>-0.027394</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>c</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n    <tr>\n      <th>16761</th>\n      <td>0.344708</td>\n      <td>0.353518</td>\n      <td>-0.772482</td>\n      <td>-0.974118</td>\n      <td>0.301341</td>\n      <td>0.341788</td>\n      <td>0.434587</td>\n      <td>0.516161</td>\n      <td>-0.173809</td>\n      <td>-0.658705</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>k</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n    </tr>\n  </tbody>\n</table>\n<p>16762 rows × 280 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm.describe()\n",
    "df = df_norm\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "         AxMean     AxMed     AxStd     AxVar     AxMax     AxMin    AyMean  \\\n0     -0.132653 -0.147185 -0.603221 -0.921283  0.032926 -0.109151  0.273847   \n1     -0.021683 -0.003086 -0.550748 -0.899086  0.045203 -0.114663  0.140869   \n2     -0.085178 -0.086068 -0.557407 -0.902056  0.027346 -0.081589  0.209052   \n3     -0.276150 -0.278387 -0.611171 -0.924406 -0.190848 -0.311467  0.018891   \n4     -0.069426 -0.068126 -0.800858 -0.980171 -0.066965 -0.066703 -0.186420   \n...         ...       ...       ...       ...       ...       ...       ...   \n16757 -0.094617 -0.091114 -0.974706 -0.999680 -0.141182 -0.024254 -0.288535   \n16758 -0.337784 -0.329409 -0.968054 -0.999490 -0.364956 -0.248069 -0.052138   \n16759 -0.442860 -0.411833 -0.905203 -0.995507 -0.460381 -0.364941 -0.085882   \n16760 -0.058369 -0.059153 -1.000000 -1.000000 -0.109373  0.017642 -0.024612   \n16761  0.344708  0.353518 -0.772482 -0.974118  0.301341  0.341788  0.434587   \n\n          AyMed     AyStd     AyVar  ...  PreVar  PreMax  PreMin  View  \\\n0      0.271777 -0.630290 -0.931657  ...    -1.0    -1.0    -1.0     t   \n1      0.087105 -0.473945 -0.861633  ...    -1.0    -1.0    -1.0     h   \n2      0.189288 -0.663520 -0.943391  ...    -1.0    -1.0    -1.0     e   \n3      0.021238 -0.675163 -0.947240  ...    -1.0    -1.0    -1.0         \n4     -0.175745 -0.781213 -0.976066  ...    -1.0    -1.0    -1.0     r   \n...         ...       ...       ...  ...     ...     ...     ...   ...   \n16757 -0.281008 -0.975331 -0.999696  ...    -1.0    -1.0    -1.0         \n16758 -0.015699 -0.662813 -0.943152  ...    -1.0    -1.0    -1.0     z   \n16759 -0.088337 -0.983483 -0.999864  ...    -1.0    -1.0    -1.0     a   \n16760 -0.027394 -1.000000 -1.000000  ...    -1.0    -1.0    -1.0     c   \n16761  0.516161 -0.173809 -0.658705  ...    -1.0    -1.0    -1.0     k   \n\n         User  Hand  Smartphone    x  y      dist  \n0      Chiara  LEFT    REALME 7  5.0  0  3.640055  \n1      Chiara  LEFT    REALME 7  6.5  1  5.000000  \n2      Chiara  LEFT    REALME 7  3.0  0  1.802776  \n3      Chiara  LEFT    REALME 7  5.0  3  4.031129  \n4      Chiara  LEFT    REALME 7  4.0  0  2.692582  \n...       ...   ...         ...  ... ..       ...  \n16757  Chiara  LEFT    REALME 7  5.0  3  4.031129  \n16758  Chiara  LEFT    REALME 7  2.0  2  1.118034  \n16759  Chiara  LEFT    REALME 7  1.5  1  0.000000  \n16760  Chiara  LEFT    REALME 7  4.0  2  2.692582  \n16761  Chiara  LEFT    REALME 7  8.5  1  7.000000  \n\n[16762 rows x 283 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AxMean</th>\n      <th>AxMed</th>\n      <th>AxStd</th>\n      <th>AxVar</th>\n      <th>AxMax</th>\n      <th>AxMin</th>\n      <th>AyMean</th>\n      <th>AyMed</th>\n      <th>AyStd</th>\n      <th>AyVar</th>\n      <th>...</th>\n      <th>PreVar</th>\n      <th>PreMax</th>\n      <th>PreMin</th>\n      <th>View</th>\n      <th>User</th>\n      <th>Hand</th>\n      <th>Smartphone</th>\n      <th>x</th>\n      <th>y</th>\n      <th>dist</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.132653</td>\n      <td>-0.147185</td>\n      <td>-0.603221</td>\n      <td>-0.921283</td>\n      <td>0.032926</td>\n      <td>-0.109151</td>\n      <td>0.273847</td>\n      <td>0.271777</td>\n      <td>-0.630290</td>\n      <td>-0.931657</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>t</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>3.640055</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.021683</td>\n      <td>-0.003086</td>\n      <td>-0.550748</td>\n      <td>-0.899086</td>\n      <td>0.045203</td>\n      <td>-0.114663</td>\n      <td>0.140869</td>\n      <td>0.087105</td>\n      <td>-0.473945</td>\n      <td>-0.861633</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>h</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>6.5</td>\n      <td>1</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.085178</td>\n      <td>-0.086068</td>\n      <td>-0.557407</td>\n      <td>-0.902056</td>\n      <td>0.027346</td>\n      <td>-0.081589</td>\n      <td>0.209052</td>\n      <td>0.189288</td>\n      <td>-0.663520</td>\n      <td>-0.943391</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>e</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>1.802776</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.276150</td>\n      <td>-0.278387</td>\n      <td>-0.611171</td>\n      <td>-0.924406</td>\n      <td>-0.190848</td>\n      <td>-0.311467</td>\n      <td>0.018891</td>\n      <td>0.021238</td>\n      <td>-0.675163</td>\n      <td>-0.947240</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td></td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>5.0</td>\n      <td>3</td>\n      <td>4.031129</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.069426</td>\n      <td>-0.068126</td>\n      <td>-0.800858</td>\n      <td>-0.980171</td>\n      <td>-0.066965</td>\n      <td>-0.066703</td>\n      <td>-0.186420</td>\n      <td>-0.175745</td>\n      <td>-0.781213</td>\n      <td>-0.976066</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>r</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>2.692582</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>16757</th>\n      <td>-0.094617</td>\n      <td>-0.091114</td>\n      <td>-0.974706</td>\n      <td>-0.999680</td>\n      <td>-0.141182</td>\n      <td>-0.024254</td>\n      <td>-0.288535</td>\n      <td>-0.281008</td>\n      <td>-0.975331</td>\n      <td>-0.999696</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td></td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>5.0</td>\n      <td>3</td>\n      <td>4.031129</td>\n    </tr>\n    <tr>\n      <th>16758</th>\n      <td>-0.337784</td>\n      <td>-0.329409</td>\n      <td>-0.968054</td>\n      <td>-0.999490</td>\n      <td>-0.364956</td>\n      <td>-0.248069</td>\n      <td>-0.052138</td>\n      <td>-0.015699</td>\n      <td>-0.662813</td>\n      <td>-0.943152</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>z</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>1.118034</td>\n    </tr>\n    <tr>\n      <th>16759</th>\n      <td>-0.442860</td>\n      <td>-0.411833</td>\n      <td>-0.905203</td>\n      <td>-0.995507</td>\n      <td>-0.460381</td>\n      <td>-0.364941</td>\n      <td>-0.085882</td>\n      <td>-0.088337</td>\n      <td>-0.983483</td>\n      <td>-0.999864</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>a</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>16760</th>\n      <td>-0.058369</td>\n      <td>-0.059153</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>-0.109373</td>\n      <td>0.017642</td>\n      <td>-0.024612</td>\n      <td>-0.027394</td>\n      <td>-1.000000</td>\n      <td>-1.000000</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>c</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>4.0</td>\n      <td>2</td>\n      <td>2.692582</td>\n    </tr>\n    <tr>\n      <th>16761</th>\n      <td>0.344708</td>\n      <td>0.353518</td>\n      <td>-0.772482</td>\n      <td>-0.974118</td>\n      <td>0.301341</td>\n      <td>0.341788</td>\n      <td>0.434587</td>\n      <td>0.516161</td>\n      <td>-0.173809</td>\n      <td>-0.658705</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>k</td>\n      <td>Chiara</td>\n      <td>LEFT</td>\n      <td>REALME 7</td>\n      <td>8.5</td>\n      <td>1</td>\n      <td>7.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>16762 rows × 283 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add letters\n",
    "letters = [\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\",\"h\",\"i\",\"j\",\"k\",\"l\",\"m\",\"n\",\"o\",\"p\",\"q\",\"r\",\"s\",\"t\",\"u\",\"v\",\"w\",\"x\",\"y\",\"z\",\" \"]\n",
    "# add distances from left margin (xAxis) and top margin (yAxis) (start from 1)\n",
    "yAxis = [ 1,  2,  2,  1,  0,  1,  1,  1,  0,  1,  1,  1,  2,  2,  0,  0,  0,  0,  1,  0,  0,  2,  0,  2,  0,  2, 3]\n",
    "xAxis =[ 1.5,  6,  4,  3.5,  3,  4.5,  5.5, 6.5,  8,  7.5, 8.5,  9.5,  8,  7,  9,  10,  1,  4,  2.5,  5,  7,  5,  2,  3,  6,  2, 5]\n",
    "\n",
    "# pair of distances for letters\n",
    "dict_letters = {}\n",
    "for i, let in enumerate(letters):\n",
    "    dict_letters[let] = (xAxis[i], yAxis[i])\n",
    "\n",
    "center = \"a\"\n",
    "dict_dist = {}\n",
    "for let in letters:\n",
    "    dict_dist[let] = math.sqrt((dict_letters[center][0] - dict_letters[let][0])**2 + (dict_letters[center][1] - dict_letters[let][1])**2)\n",
    "\n",
    "# write in df distances and dist from center\n",
    "df.loc[:,'x'] = df.apply(lambda x: dict_letters[x['View']][0], axis=1)\n",
    "df.loc[:,'y'] = df.apply(lambda x: dict_letters[x['View']][1], axis=1)\n",
    "df.loc[:,'dist'] = df.apply(lambda x: dict_dist[x['View']], axis=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   View      dist     x  y    AxMean     AxMed     AxStd     AxVar     AxMax  \\\n0        4.031129   5.0  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n1     a  0.000000   1.5  1 -0.442607 -0.414158 -0.674681 -0.909059 -0.411576   \n2     b  4.609772   6.0  2  0.033203  0.023504 -0.788821 -0.954436  0.030797   \n3     c  2.692582   4.0  2 -0.110353 -0.109572 -0.829623 -0.968095 -0.119691   \n4     d  2.000000   3.5  1 -0.171691 -0.166162 -0.843684 -0.974481 -0.181909   \n5     e  1.802776   3.0  0 -0.219282 -0.213487 -0.830212 -0.972243 -0.222810   \n6     f  3.000000   4.5  1 -0.110754 -0.111648 -0.824161 -0.969190 -0.118787   \n7     g  4.000000   5.5  1 -0.017499 -0.022905 -0.832367 -0.971224 -0.030099   \n8     h  5.000000   6.5  1  0.102653  0.091987 -0.794797 -0.960715  0.092600   \n9     i  6.576473   8.0  0  0.289857  0.268957 -0.735985 -0.930639  0.286954   \n10    j  6.000000   7.5  1  0.203782  0.183908 -0.744169 -0.937484  0.204834   \n11    k  7.000000   8.5  1  0.290610  0.274432 -0.714272 -0.921840  0.291558   \n12    l  8.000000   9.5  1  0.362521  0.333457 -0.607098 -0.864886  0.392674   \n13    m  6.576473   8.0  2  0.208654  0.184352 -0.710656 -0.917444  0.220686   \n14    n  5.590170   7.0  2  0.068592  0.053889 -0.773316 -0.948108  0.071762   \n15    o  7.566373   9.0  0  0.371027  0.345269 -0.653884 -0.892367  0.387984   \n16    p  8.558621  10.0  0  0.514173  0.485435 -0.541115 -0.809638  0.547359   \n17    q  1.118034   1.0  0 -0.491990 -0.460261 -0.645030 -0.902022 -0.451546   \n18    r  2.692582   4.0  0 -0.095784 -0.095631 -0.827752 -0.972050 -0.104678   \n19    s  1.000000   2.5  1 -0.253098 -0.239868 -0.801915 -0.961876 -0.254747   \n20    t  3.640055   5.0  0 -0.017209 -0.025598 -0.784171 -0.955580 -0.016020   \n21    u  5.590170   7.0  0  0.189590  0.171600 -0.762683 -0.944200  0.187224   \n22    v  3.640055   5.0  2 -0.026683 -0.029301 -0.804434 -0.964422 -0.034225   \n23    w  1.118034   2.0  0 -0.290480 -0.277180 -0.811823 -0.964282 -0.290284   \n24    x  1.802776   3.0  2 -0.161558 -0.153478 -0.790553 -0.957638 -0.158937   \n25    y  4.609772   6.0  0  0.108119  0.095498 -0.829017 -0.967917  0.091622   \n26    z  1.118034   2.0  2 -0.318231 -0.302339 -0.740874 -0.939725 -0.302288   \n\n       AxMin  ...  GrPitchStd  GrPitchVar  GrPitchMax  GrPitchMin  PreMean  \\\n0  -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n1  -0.427211  ...   -0.625560   -0.894337    0.422748    0.442984     -1.0   \n2   0.058167  ...   -0.754772   -0.945768   -0.026646   -0.001717     -1.0   \n3  -0.071302  ...   -0.734215   -0.938614    0.108551    0.135588     -1.0   \n4  -0.127884  ...   -0.738169   -0.943789    0.158329    0.187836     -1.0   \n5  -0.173440  ...   -0.747517   -0.947119    0.197392    0.228557     -1.0   \n6  -0.072111  ...   -0.755293   -0.951283    0.088726    0.117399     -1.0   \n7   0.015641  ...   -0.781298   -0.958011    0.022183    0.052845     -1.0   \n8   0.121151  ...   -0.762427   -0.950764   -0.083734   -0.060005     -1.0   \n9   0.288349  ...   -0.725372   -0.934015   -0.264608   -0.252564     -1.0   \n10  0.210062  ...   -0.750580   -0.942825   -0.176624   -0.156995     -1.0   \n11  0.282225  ...   -0.718983   -0.931762   -0.249039   -0.237900     -1.0   \n12  0.333926  ...   -0.716321   -0.932508   -0.342132   -0.334865     -1.0   \n13  0.208433  ...   -0.757747   -0.946598   -0.205375   -0.186145     -1.0   \n14  0.090965  ...   -0.797187   -0.962993   -0.068985   -0.039082     -1.0   \n15  0.349645  ...   -0.710925   -0.931444   -0.341413   -0.335645     -1.0   \n16  0.456878  ...   -0.633513   -0.889970   -0.451970   -0.462430     -1.0   \n17 -0.483028  ...   -0.593257   -0.880001    0.473229    0.488232     -1.0   \n18 -0.057278  ...   -0.758218   -0.949282    0.084262    0.113292     -1.0   \n19 -0.216863  ...   -0.686286   -0.922792    0.247783    0.272937     -1.0   \n20  0.009953  ...   -0.752453   -0.946405    0.008669    0.033927     -1.0   \n21  0.202541  ...   -0.728503   -0.938528   -0.168419   -0.152817     -1.0   \n22  0.001689  ...   -0.794487   -0.961904    0.030610    0.063340     -1.0   \n23 -0.248117  ...   -0.689123   -0.922525    0.275227    0.301285     -1.0   \n24 -0.130475  ...   -0.721780   -0.938717    0.149529    0.175831     -1.0   \n25  0.137070  ...   -0.788343   -0.958688   -0.103080   -0.075300     -1.0   \n26 -0.293202  ...   -0.642970   -0.898474    0.307220    0.326634     -1.0   \n\n    PreMed  PreStd  PreVar  PreMax  PreMin  \n0     -1.0    -1.0    -1.0    -1.0    -1.0  \n1     -1.0    -1.0    -1.0    -1.0    -1.0  \n2     -1.0    -1.0    -1.0    -1.0    -1.0  \n3     -1.0    -1.0    -1.0    -1.0    -1.0  \n4     -1.0    -1.0    -1.0    -1.0    -1.0  \n5     -1.0    -1.0    -1.0    -1.0    -1.0  \n6     -1.0    -1.0    -1.0    -1.0    -1.0  \n7     -1.0    -1.0    -1.0    -1.0    -1.0  \n8     -1.0    -1.0    -1.0    -1.0    -1.0  \n9     -1.0    -1.0    -1.0    -1.0    -1.0  \n10    -1.0    -1.0    -1.0    -1.0    -1.0  \n11    -1.0    -1.0    -1.0    -1.0    -1.0  \n12    -1.0    -1.0    -1.0    -1.0    -1.0  \n13    -1.0    -1.0    -1.0    -1.0    -1.0  \n14    -1.0    -1.0    -1.0    -1.0    -1.0  \n15    -1.0    -1.0    -1.0    -1.0    -1.0  \n16    -1.0    -1.0    -1.0    -1.0    -1.0  \n17    -1.0    -1.0    -1.0    -1.0    -1.0  \n18    -1.0    -1.0    -1.0    -1.0    -1.0  \n19    -1.0    -1.0    -1.0    -1.0    -1.0  \n20    -1.0    -1.0    -1.0    -1.0    -1.0  \n21    -1.0    -1.0    -1.0    -1.0    -1.0  \n22    -1.0    -1.0    -1.0    -1.0    -1.0  \n23    -1.0    -1.0    -1.0    -1.0    -1.0  \n24    -1.0    -1.0    -1.0    -1.0    -1.0  \n25    -1.0    -1.0    -1.0    -1.0    -1.0  \n26    -1.0    -1.0    -1.0    -1.0    -1.0  \n\n[27 rows x 280 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>View</th>\n      <th>dist</th>\n      <th>x</th>\n      <th>y</th>\n      <th>AxMean</th>\n      <th>AxMed</th>\n      <th>AxStd</th>\n      <th>AxVar</th>\n      <th>AxMax</th>\n      <th>AxMin</th>\n      <th>...</th>\n      <th>GrPitchStd</th>\n      <th>GrPitchVar</th>\n      <th>GrPitchMax</th>\n      <th>GrPitchMin</th>\n      <th>PreMean</th>\n      <th>PreMed</th>\n      <th>PreStd</th>\n      <th>PreVar</th>\n      <th>PreMax</th>\n      <th>PreMin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>5.0</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>-0.442607</td>\n      <td>-0.414158</td>\n      <td>-0.674681</td>\n      <td>-0.909059</td>\n      <td>-0.411576</td>\n      <td>-0.427211</td>\n      <td>...</td>\n      <td>-0.625560</td>\n      <td>-0.894337</td>\n      <td>0.422748</td>\n      <td>0.442984</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b</td>\n      <td>4.609772</td>\n      <td>6.0</td>\n      <td>2</td>\n      <td>0.033203</td>\n      <td>0.023504</td>\n      <td>-0.788821</td>\n      <td>-0.954436</td>\n      <td>0.030797</td>\n      <td>0.058167</td>\n      <td>...</td>\n      <td>-0.754772</td>\n      <td>-0.945768</td>\n      <td>-0.026646</td>\n      <td>-0.001717</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c</td>\n      <td>2.692582</td>\n      <td>4.0</td>\n      <td>2</td>\n      <td>-0.110353</td>\n      <td>-0.109572</td>\n      <td>-0.829623</td>\n      <td>-0.968095</td>\n      <td>-0.119691</td>\n      <td>-0.071302</td>\n      <td>...</td>\n      <td>-0.734215</td>\n      <td>-0.938614</td>\n      <td>0.108551</td>\n      <td>0.135588</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>d</td>\n      <td>2.000000</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>-0.171691</td>\n      <td>-0.166162</td>\n      <td>-0.843684</td>\n      <td>-0.974481</td>\n      <td>-0.181909</td>\n      <td>-0.127884</td>\n      <td>...</td>\n      <td>-0.738169</td>\n      <td>-0.943789</td>\n      <td>0.158329</td>\n      <td>0.187836</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>e</td>\n      <td>1.802776</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>-0.219282</td>\n      <td>-0.213487</td>\n      <td>-0.830212</td>\n      <td>-0.972243</td>\n      <td>-0.222810</td>\n      <td>-0.173440</td>\n      <td>...</td>\n      <td>-0.747517</td>\n      <td>-0.947119</td>\n      <td>0.197392</td>\n      <td>0.228557</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f</td>\n      <td>3.000000</td>\n      <td>4.5</td>\n      <td>1</td>\n      <td>-0.110754</td>\n      <td>-0.111648</td>\n      <td>-0.824161</td>\n      <td>-0.969190</td>\n      <td>-0.118787</td>\n      <td>-0.072111</td>\n      <td>...</td>\n      <td>-0.755293</td>\n      <td>-0.951283</td>\n      <td>0.088726</td>\n      <td>0.117399</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>g</td>\n      <td>4.000000</td>\n      <td>5.5</td>\n      <td>1</td>\n      <td>-0.017499</td>\n      <td>-0.022905</td>\n      <td>-0.832367</td>\n      <td>-0.971224</td>\n      <td>-0.030099</td>\n      <td>0.015641</td>\n      <td>...</td>\n      <td>-0.781298</td>\n      <td>-0.958011</td>\n      <td>0.022183</td>\n      <td>0.052845</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>h</td>\n      <td>5.000000</td>\n      <td>6.5</td>\n      <td>1</td>\n      <td>0.102653</td>\n      <td>0.091987</td>\n      <td>-0.794797</td>\n      <td>-0.960715</td>\n      <td>0.092600</td>\n      <td>0.121151</td>\n      <td>...</td>\n      <td>-0.762427</td>\n      <td>-0.950764</td>\n      <td>-0.083734</td>\n      <td>-0.060005</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>i</td>\n      <td>6.576473</td>\n      <td>8.0</td>\n      <td>0</td>\n      <td>0.289857</td>\n      <td>0.268957</td>\n      <td>-0.735985</td>\n      <td>-0.930639</td>\n      <td>0.286954</td>\n      <td>0.288349</td>\n      <td>...</td>\n      <td>-0.725372</td>\n      <td>-0.934015</td>\n      <td>-0.264608</td>\n      <td>-0.252564</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>j</td>\n      <td>6.000000</td>\n      <td>7.5</td>\n      <td>1</td>\n      <td>0.203782</td>\n      <td>0.183908</td>\n      <td>-0.744169</td>\n      <td>-0.937484</td>\n      <td>0.204834</td>\n      <td>0.210062</td>\n      <td>...</td>\n      <td>-0.750580</td>\n      <td>-0.942825</td>\n      <td>-0.176624</td>\n      <td>-0.156995</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>k</td>\n      <td>7.000000</td>\n      <td>8.5</td>\n      <td>1</td>\n      <td>0.290610</td>\n      <td>0.274432</td>\n      <td>-0.714272</td>\n      <td>-0.921840</td>\n      <td>0.291558</td>\n      <td>0.282225</td>\n      <td>...</td>\n      <td>-0.718983</td>\n      <td>-0.931762</td>\n      <td>-0.249039</td>\n      <td>-0.237900</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>l</td>\n      <td>8.000000</td>\n      <td>9.5</td>\n      <td>1</td>\n      <td>0.362521</td>\n      <td>0.333457</td>\n      <td>-0.607098</td>\n      <td>-0.864886</td>\n      <td>0.392674</td>\n      <td>0.333926</td>\n      <td>...</td>\n      <td>-0.716321</td>\n      <td>-0.932508</td>\n      <td>-0.342132</td>\n      <td>-0.334865</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>m</td>\n      <td>6.576473</td>\n      <td>8.0</td>\n      <td>2</td>\n      <td>0.208654</td>\n      <td>0.184352</td>\n      <td>-0.710656</td>\n      <td>-0.917444</td>\n      <td>0.220686</td>\n      <td>0.208433</td>\n      <td>...</td>\n      <td>-0.757747</td>\n      <td>-0.946598</td>\n      <td>-0.205375</td>\n      <td>-0.186145</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>n</td>\n      <td>5.590170</td>\n      <td>7.0</td>\n      <td>2</td>\n      <td>0.068592</td>\n      <td>0.053889</td>\n      <td>-0.773316</td>\n      <td>-0.948108</td>\n      <td>0.071762</td>\n      <td>0.090965</td>\n      <td>...</td>\n      <td>-0.797187</td>\n      <td>-0.962993</td>\n      <td>-0.068985</td>\n      <td>-0.039082</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>o</td>\n      <td>7.566373</td>\n      <td>9.0</td>\n      <td>0</td>\n      <td>0.371027</td>\n      <td>0.345269</td>\n      <td>-0.653884</td>\n      <td>-0.892367</td>\n      <td>0.387984</td>\n      <td>0.349645</td>\n      <td>...</td>\n      <td>-0.710925</td>\n      <td>-0.931444</td>\n      <td>-0.341413</td>\n      <td>-0.335645</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>p</td>\n      <td>8.558621</td>\n      <td>10.0</td>\n      <td>0</td>\n      <td>0.514173</td>\n      <td>0.485435</td>\n      <td>-0.541115</td>\n      <td>-0.809638</td>\n      <td>0.547359</td>\n      <td>0.456878</td>\n      <td>...</td>\n      <td>-0.633513</td>\n      <td>-0.889970</td>\n      <td>-0.451970</td>\n      <td>-0.462430</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>q</td>\n      <td>1.118034</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>-0.491990</td>\n      <td>-0.460261</td>\n      <td>-0.645030</td>\n      <td>-0.902022</td>\n      <td>-0.451546</td>\n      <td>-0.483028</td>\n      <td>...</td>\n      <td>-0.593257</td>\n      <td>-0.880001</td>\n      <td>0.473229</td>\n      <td>0.488232</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>r</td>\n      <td>2.692582</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>-0.095784</td>\n      <td>-0.095631</td>\n      <td>-0.827752</td>\n      <td>-0.972050</td>\n      <td>-0.104678</td>\n      <td>-0.057278</td>\n      <td>...</td>\n      <td>-0.758218</td>\n      <td>-0.949282</td>\n      <td>0.084262</td>\n      <td>0.113292</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>s</td>\n      <td>1.000000</td>\n      <td>2.5</td>\n      <td>1</td>\n      <td>-0.253098</td>\n      <td>-0.239868</td>\n      <td>-0.801915</td>\n      <td>-0.961876</td>\n      <td>-0.254747</td>\n      <td>-0.216863</td>\n      <td>...</td>\n      <td>-0.686286</td>\n      <td>-0.922792</td>\n      <td>0.247783</td>\n      <td>0.272937</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>t</td>\n      <td>3.640055</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>-0.017209</td>\n      <td>-0.025598</td>\n      <td>-0.784171</td>\n      <td>-0.955580</td>\n      <td>-0.016020</td>\n      <td>0.009953</td>\n      <td>...</td>\n      <td>-0.752453</td>\n      <td>-0.946405</td>\n      <td>0.008669</td>\n      <td>0.033927</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>u</td>\n      <td>5.590170</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>0.189590</td>\n      <td>0.171600</td>\n      <td>-0.762683</td>\n      <td>-0.944200</td>\n      <td>0.187224</td>\n      <td>0.202541</td>\n      <td>...</td>\n      <td>-0.728503</td>\n      <td>-0.938528</td>\n      <td>-0.168419</td>\n      <td>-0.152817</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>v</td>\n      <td>3.640055</td>\n      <td>5.0</td>\n      <td>2</td>\n      <td>-0.026683</td>\n      <td>-0.029301</td>\n      <td>-0.804434</td>\n      <td>-0.964422</td>\n      <td>-0.034225</td>\n      <td>0.001689</td>\n      <td>...</td>\n      <td>-0.794487</td>\n      <td>-0.961904</td>\n      <td>0.030610</td>\n      <td>0.063340</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>w</td>\n      <td>1.118034</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>-0.290480</td>\n      <td>-0.277180</td>\n      <td>-0.811823</td>\n      <td>-0.964282</td>\n      <td>-0.290284</td>\n      <td>-0.248117</td>\n      <td>...</td>\n      <td>-0.689123</td>\n      <td>-0.922525</td>\n      <td>0.275227</td>\n      <td>0.301285</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>x</td>\n      <td>1.802776</td>\n      <td>3.0</td>\n      <td>2</td>\n      <td>-0.161558</td>\n      <td>-0.153478</td>\n      <td>-0.790553</td>\n      <td>-0.957638</td>\n      <td>-0.158937</td>\n      <td>-0.130475</td>\n      <td>...</td>\n      <td>-0.721780</td>\n      <td>-0.938717</td>\n      <td>0.149529</td>\n      <td>0.175831</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>y</td>\n      <td>4.609772</td>\n      <td>6.0</td>\n      <td>0</td>\n      <td>0.108119</td>\n      <td>0.095498</td>\n      <td>-0.829017</td>\n      <td>-0.967917</td>\n      <td>0.091622</td>\n      <td>0.137070</td>\n      <td>...</td>\n      <td>-0.788343</td>\n      <td>-0.958688</td>\n      <td>-0.103080</td>\n      <td>-0.075300</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>z</td>\n      <td>1.118034</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>-0.318231</td>\n      <td>-0.302339</td>\n      <td>-0.740874</td>\n      <td>-0.939725</td>\n      <td>-0.302288</td>\n      <td>-0.293202</td>\n      <td>...</td>\n      <td>-0.642970</td>\n      <td>-0.898474</td>\n      <td>0.307220</td>\n      <td>0.326634</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>27 rows × 280 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group dataset by letter/distance\n",
    "\n",
    "# mean = mean of the rows with the same View and distances\n",
    "df_mean = df.groupby(['View','dist','x','y'], as_index=False).agg('mean')\n",
    "df_mean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0 3.0\n",
      "5.0 3.5\n",
      "5.0 4.0\n",
      "5.0 4.5\n",
      "5.0 5.0\n",
      "5.0 5.5\n",
      "5.0 6.0\n",
      "5.0 6.5\n",
      "5.0 7.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "   View      dist     x  y    AxMean     AxMed     AxStd     AxVar     AxMax  \\\n0        4.031129   5.0  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n1     a  0.000000   1.5  1 -0.442607 -0.414158 -0.674681 -0.909059 -0.411576   \n2     b  4.609772   6.0  2  0.033203  0.023504 -0.788821 -0.954436  0.030797   \n3     c  2.692582   4.0  2 -0.110353 -0.109572 -0.829623 -0.968095 -0.119691   \n4     d  2.000000   3.5  1 -0.171691 -0.166162 -0.843684 -0.974481 -0.181909   \n5     e  1.802776   3.0  0 -0.219282 -0.213487 -0.830212 -0.972243 -0.222810   \n6     f  3.000000   4.5  1 -0.110754 -0.111648 -0.824161 -0.969190 -0.118787   \n7     g  4.000000   5.5  1 -0.017499 -0.022905 -0.832367 -0.971224 -0.030099   \n8     h  5.000000   6.5  1  0.102653  0.091987 -0.794797 -0.960715  0.092600   \n9     i  6.576473   8.0  0  0.289857  0.268957 -0.735985 -0.930639  0.286954   \n10    j  6.000000   7.5  1  0.203782  0.183908 -0.744169 -0.937484  0.204834   \n11    k  7.000000   8.5  1  0.290610  0.274432 -0.714272 -0.921840  0.291558   \n12    l  8.000000   9.5  1  0.362521  0.333457 -0.607098 -0.864886  0.392674   \n13    m  6.576473   8.0  2  0.208654  0.184352 -0.710656 -0.917444  0.220686   \n14    n  5.590170   7.0  2  0.068592  0.053889 -0.773316 -0.948108  0.071762   \n15    o  7.566373   9.0  0  0.371027  0.345269 -0.653884 -0.892367  0.387984   \n16    p  8.558621  10.0  0  0.514173  0.485435 -0.541115 -0.809638  0.547359   \n17    q  1.118034   1.0  0 -0.491990 -0.460261 -0.645030 -0.902022 -0.451546   \n18    r  2.692582   4.0  0 -0.095784 -0.095631 -0.827752 -0.972050 -0.104678   \n19    s  1.000000   2.5  1 -0.253098 -0.239868 -0.801915 -0.961876 -0.254747   \n20    t  3.640055   5.0  0 -0.017209 -0.025598 -0.784171 -0.955580 -0.016020   \n21    u  5.590170   7.0  0  0.189590  0.171600 -0.762683 -0.944200  0.187224   \n22    v  3.640055   5.0  2 -0.026683 -0.029301 -0.804434 -0.964422 -0.034225   \n23    w  1.118034   2.0  0 -0.290480 -0.277180 -0.811823 -0.964282 -0.290284   \n24    x  1.802776   3.0  2 -0.161558 -0.153478 -0.790553 -0.957638 -0.158937   \n25    y  4.609772   6.0  0  0.108119  0.095498 -0.829017 -0.967917  0.091622   \n26    z  1.118034   2.0  2 -0.318231 -0.302339 -0.740874 -0.939725 -0.302288   \n27       4.031129   3.0  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n28       4.031129   3.5  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n29       4.031129   4.0  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n30       4.031129   4.5  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n31       4.031129   5.5  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n32       4.031129   6.0  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n33       4.031129   6.5  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n34       4.031129   7.0  3 -0.159617 -0.154432 -0.821499 -0.968070 -0.166154   \n\n       AxMin  ...  GrPitchStd  GrPitchVar  GrPitchMax  GrPitchMin  PreMean  \\\n0  -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n1  -0.427211  ...   -0.625560   -0.894337    0.422748    0.442984     -1.0   \n2   0.058167  ...   -0.754772   -0.945768   -0.026646   -0.001717     -1.0   \n3  -0.071302  ...   -0.734215   -0.938614    0.108551    0.135588     -1.0   \n4  -0.127884  ...   -0.738169   -0.943789    0.158329    0.187836     -1.0   \n5  -0.173440  ...   -0.747517   -0.947119    0.197392    0.228557     -1.0   \n6  -0.072111  ...   -0.755293   -0.951283    0.088726    0.117399     -1.0   \n7   0.015641  ...   -0.781298   -0.958011    0.022183    0.052845     -1.0   \n8   0.121151  ...   -0.762427   -0.950764   -0.083734   -0.060005     -1.0   \n9   0.288349  ...   -0.725372   -0.934015   -0.264608   -0.252564     -1.0   \n10  0.210062  ...   -0.750580   -0.942825   -0.176624   -0.156995     -1.0   \n11  0.282225  ...   -0.718983   -0.931762   -0.249039   -0.237900     -1.0   \n12  0.333926  ...   -0.716321   -0.932508   -0.342132   -0.334865     -1.0   \n13  0.208433  ...   -0.757747   -0.946598   -0.205375   -0.186145     -1.0   \n14  0.090965  ...   -0.797187   -0.962993   -0.068985   -0.039082     -1.0   \n15  0.349645  ...   -0.710925   -0.931444   -0.341413   -0.335645     -1.0   \n16  0.456878  ...   -0.633513   -0.889970   -0.451970   -0.462430     -1.0   \n17 -0.483028  ...   -0.593257   -0.880001    0.473229    0.488232     -1.0   \n18 -0.057278  ...   -0.758218   -0.949282    0.084262    0.113292     -1.0   \n19 -0.216863  ...   -0.686286   -0.922792    0.247783    0.272937     -1.0   \n20  0.009953  ...   -0.752453   -0.946405    0.008669    0.033927     -1.0   \n21  0.202541  ...   -0.728503   -0.938528   -0.168419   -0.152817     -1.0   \n22  0.001689  ...   -0.794487   -0.961904    0.030610    0.063340     -1.0   \n23 -0.248117  ...   -0.689123   -0.922525    0.275227    0.301285     -1.0   \n24 -0.130475  ...   -0.721780   -0.938717    0.149529    0.175831     -1.0   \n25  0.137070  ...   -0.788343   -0.958688   -0.103080   -0.075300     -1.0   \n26 -0.293202  ...   -0.642970   -0.898474    0.307220    0.326634     -1.0   \n27 -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n28 -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n29 -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n30 -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n31 -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n32 -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n33 -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n34 -0.121125  ...   -0.800410   -0.964268    0.145335    0.183078     -1.0   \n\n    PreMed  PreStd  PreVar  PreMax  PreMin  \n0     -1.0    -1.0    -1.0    -1.0    -1.0  \n1     -1.0    -1.0    -1.0    -1.0    -1.0  \n2     -1.0    -1.0    -1.0    -1.0    -1.0  \n3     -1.0    -1.0    -1.0    -1.0    -1.0  \n4     -1.0    -1.0    -1.0    -1.0    -1.0  \n5     -1.0    -1.0    -1.0    -1.0    -1.0  \n6     -1.0    -1.0    -1.0    -1.0    -1.0  \n7     -1.0    -1.0    -1.0    -1.0    -1.0  \n8     -1.0    -1.0    -1.0    -1.0    -1.0  \n9     -1.0    -1.0    -1.0    -1.0    -1.0  \n10    -1.0    -1.0    -1.0    -1.0    -1.0  \n11    -1.0    -1.0    -1.0    -1.0    -1.0  \n12    -1.0    -1.0    -1.0    -1.0    -1.0  \n13    -1.0    -1.0    -1.0    -1.0    -1.0  \n14    -1.0    -1.0    -1.0    -1.0    -1.0  \n15    -1.0    -1.0    -1.0    -1.0    -1.0  \n16    -1.0    -1.0    -1.0    -1.0    -1.0  \n17    -1.0    -1.0    -1.0    -1.0    -1.0  \n18    -1.0    -1.0    -1.0    -1.0    -1.0  \n19    -1.0    -1.0    -1.0    -1.0    -1.0  \n20    -1.0    -1.0    -1.0    -1.0    -1.0  \n21    -1.0    -1.0    -1.0    -1.0    -1.0  \n22    -1.0    -1.0    -1.0    -1.0    -1.0  \n23    -1.0    -1.0    -1.0    -1.0    -1.0  \n24    -1.0    -1.0    -1.0    -1.0    -1.0  \n25    -1.0    -1.0    -1.0    -1.0    -1.0  \n26    -1.0    -1.0    -1.0    -1.0    -1.0  \n27    -1.0    -1.0    -1.0    -1.0    -1.0  \n28    -1.0    -1.0    -1.0    -1.0    -1.0  \n29    -1.0    -1.0    -1.0    -1.0    -1.0  \n30    -1.0    -1.0    -1.0    -1.0    -1.0  \n31    -1.0    -1.0    -1.0    -1.0    -1.0  \n32    -1.0    -1.0    -1.0    -1.0    -1.0  \n33    -1.0    -1.0    -1.0    -1.0    -1.0  \n34    -1.0    -1.0    -1.0    -1.0    -1.0  \n\n[35 rows x 280 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>View</th>\n      <th>dist</th>\n      <th>x</th>\n      <th>y</th>\n      <th>AxMean</th>\n      <th>AxMed</th>\n      <th>AxStd</th>\n      <th>AxVar</th>\n      <th>AxMax</th>\n      <th>AxMin</th>\n      <th>...</th>\n      <th>GrPitchStd</th>\n      <th>GrPitchVar</th>\n      <th>GrPitchMax</th>\n      <th>GrPitchMin</th>\n      <th>PreMean</th>\n      <th>PreMed</th>\n      <th>PreStd</th>\n      <th>PreVar</th>\n      <th>PreMax</th>\n      <th>PreMin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>5.0</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a</td>\n      <td>0.000000</td>\n      <td>1.5</td>\n      <td>1</td>\n      <td>-0.442607</td>\n      <td>-0.414158</td>\n      <td>-0.674681</td>\n      <td>-0.909059</td>\n      <td>-0.411576</td>\n      <td>-0.427211</td>\n      <td>...</td>\n      <td>-0.625560</td>\n      <td>-0.894337</td>\n      <td>0.422748</td>\n      <td>0.442984</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b</td>\n      <td>4.609772</td>\n      <td>6.0</td>\n      <td>2</td>\n      <td>0.033203</td>\n      <td>0.023504</td>\n      <td>-0.788821</td>\n      <td>-0.954436</td>\n      <td>0.030797</td>\n      <td>0.058167</td>\n      <td>...</td>\n      <td>-0.754772</td>\n      <td>-0.945768</td>\n      <td>-0.026646</td>\n      <td>-0.001717</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>c</td>\n      <td>2.692582</td>\n      <td>4.0</td>\n      <td>2</td>\n      <td>-0.110353</td>\n      <td>-0.109572</td>\n      <td>-0.829623</td>\n      <td>-0.968095</td>\n      <td>-0.119691</td>\n      <td>-0.071302</td>\n      <td>...</td>\n      <td>-0.734215</td>\n      <td>-0.938614</td>\n      <td>0.108551</td>\n      <td>0.135588</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>d</td>\n      <td>2.000000</td>\n      <td>3.5</td>\n      <td>1</td>\n      <td>-0.171691</td>\n      <td>-0.166162</td>\n      <td>-0.843684</td>\n      <td>-0.974481</td>\n      <td>-0.181909</td>\n      <td>-0.127884</td>\n      <td>...</td>\n      <td>-0.738169</td>\n      <td>-0.943789</td>\n      <td>0.158329</td>\n      <td>0.187836</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>e</td>\n      <td>1.802776</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>-0.219282</td>\n      <td>-0.213487</td>\n      <td>-0.830212</td>\n      <td>-0.972243</td>\n      <td>-0.222810</td>\n      <td>-0.173440</td>\n      <td>...</td>\n      <td>-0.747517</td>\n      <td>-0.947119</td>\n      <td>0.197392</td>\n      <td>0.228557</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>f</td>\n      <td>3.000000</td>\n      <td>4.5</td>\n      <td>1</td>\n      <td>-0.110754</td>\n      <td>-0.111648</td>\n      <td>-0.824161</td>\n      <td>-0.969190</td>\n      <td>-0.118787</td>\n      <td>-0.072111</td>\n      <td>...</td>\n      <td>-0.755293</td>\n      <td>-0.951283</td>\n      <td>0.088726</td>\n      <td>0.117399</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>g</td>\n      <td>4.000000</td>\n      <td>5.5</td>\n      <td>1</td>\n      <td>-0.017499</td>\n      <td>-0.022905</td>\n      <td>-0.832367</td>\n      <td>-0.971224</td>\n      <td>-0.030099</td>\n      <td>0.015641</td>\n      <td>...</td>\n      <td>-0.781298</td>\n      <td>-0.958011</td>\n      <td>0.022183</td>\n      <td>0.052845</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>h</td>\n      <td>5.000000</td>\n      <td>6.5</td>\n      <td>1</td>\n      <td>0.102653</td>\n      <td>0.091987</td>\n      <td>-0.794797</td>\n      <td>-0.960715</td>\n      <td>0.092600</td>\n      <td>0.121151</td>\n      <td>...</td>\n      <td>-0.762427</td>\n      <td>-0.950764</td>\n      <td>-0.083734</td>\n      <td>-0.060005</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>i</td>\n      <td>6.576473</td>\n      <td>8.0</td>\n      <td>0</td>\n      <td>0.289857</td>\n      <td>0.268957</td>\n      <td>-0.735985</td>\n      <td>-0.930639</td>\n      <td>0.286954</td>\n      <td>0.288349</td>\n      <td>...</td>\n      <td>-0.725372</td>\n      <td>-0.934015</td>\n      <td>-0.264608</td>\n      <td>-0.252564</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>j</td>\n      <td>6.000000</td>\n      <td>7.5</td>\n      <td>1</td>\n      <td>0.203782</td>\n      <td>0.183908</td>\n      <td>-0.744169</td>\n      <td>-0.937484</td>\n      <td>0.204834</td>\n      <td>0.210062</td>\n      <td>...</td>\n      <td>-0.750580</td>\n      <td>-0.942825</td>\n      <td>-0.176624</td>\n      <td>-0.156995</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>k</td>\n      <td>7.000000</td>\n      <td>8.5</td>\n      <td>1</td>\n      <td>0.290610</td>\n      <td>0.274432</td>\n      <td>-0.714272</td>\n      <td>-0.921840</td>\n      <td>0.291558</td>\n      <td>0.282225</td>\n      <td>...</td>\n      <td>-0.718983</td>\n      <td>-0.931762</td>\n      <td>-0.249039</td>\n      <td>-0.237900</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>l</td>\n      <td>8.000000</td>\n      <td>9.5</td>\n      <td>1</td>\n      <td>0.362521</td>\n      <td>0.333457</td>\n      <td>-0.607098</td>\n      <td>-0.864886</td>\n      <td>0.392674</td>\n      <td>0.333926</td>\n      <td>...</td>\n      <td>-0.716321</td>\n      <td>-0.932508</td>\n      <td>-0.342132</td>\n      <td>-0.334865</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>m</td>\n      <td>6.576473</td>\n      <td>8.0</td>\n      <td>2</td>\n      <td>0.208654</td>\n      <td>0.184352</td>\n      <td>-0.710656</td>\n      <td>-0.917444</td>\n      <td>0.220686</td>\n      <td>0.208433</td>\n      <td>...</td>\n      <td>-0.757747</td>\n      <td>-0.946598</td>\n      <td>-0.205375</td>\n      <td>-0.186145</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>n</td>\n      <td>5.590170</td>\n      <td>7.0</td>\n      <td>2</td>\n      <td>0.068592</td>\n      <td>0.053889</td>\n      <td>-0.773316</td>\n      <td>-0.948108</td>\n      <td>0.071762</td>\n      <td>0.090965</td>\n      <td>...</td>\n      <td>-0.797187</td>\n      <td>-0.962993</td>\n      <td>-0.068985</td>\n      <td>-0.039082</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>o</td>\n      <td>7.566373</td>\n      <td>9.0</td>\n      <td>0</td>\n      <td>0.371027</td>\n      <td>0.345269</td>\n      <td>-0.653884</td>\n      <td>-0.892367</td>\n      <td>0.387984</td>\n      <td>0.349645</td>\n      <td>...</td>\n      <td>-0.710925</td>\n      <td>-0.931444</td>\n      <td>-0.341413</td>\n      <td>-0.335645</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>p</td>\n      <td>8.558621</td>\n      <td>10.0</td>\n      <td>0</td>\n      <td>0.514173</td>\n      <td>0.485435</td>\n      <td>-0.541115</td>\n      <td>-0.809638</td>\n      <td>0.547359</td>\n      <td>0.456878</td>\n      <td>...</td>\n      <td>-0.633513</td>\n      <td>-0.889970</td>\n      <td>-0.451970</td>\n      <td>-0.462430</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>q</td>\n      <td>1.118034</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>-0.491990</td>\n      <td>-0.460261</td>\n      <td>-0.645030</td>\n      <td>-0.902022</td>\n      <td>-0.451546</td>\n      <td>-0.483028</td>\n      <td>...</td>\n      <td>-0.593257</td>\n      <td>-0.880001</td>\n      <td>0.473229</td>\n      <td>0.488232</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>r</td>\n      <td>2.692582</td>\n      <td>4.0</td>\n      <td>0</td>\n      <td>-0.095784</td>\n      <td>-0.095631</td>\n      <td>-0.827752</td>\n      <td>-0.972050</td>\n      <td>-0.104678</td>\n      <td>-0.057278</td>\n      <td>...</td>\n      <td>-0.758218</td>\n      <td>-0.949282</td>\n      <td>0.084262</td>\n      <td>0.113292</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>s</td>\n      <td>1.000000</td>\n      <td>2.5</td>\n      <td>1</td>\n      <td>-0.253098</td>\n      <td>-0.239868</td>\n      <td>-0.801915</td>\n      <td>-0.961876</td>\n      <td>-0.254747</td>\n      <td>-0.216863</td>\n      <td>...</td>\n      <td>-0.686286</td>\n      <td>-0.922792</td>\n      <td>0.247783</td>\n      <td>0.272937</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>t</td>\n      <td>3.640055</td>\n      <td>5.0</td>\n      <td>0</td>\n      <td>-0.017209</td>\n      <td>-0.025598</td>\n      <td>-0.784171</td>\n      <td>-0.955580</td>\n      <td>-0.016020</td>\n      <td>0.009953</td>\n      <td>...</td>\n      <td>-0.752453</td>\n      <td>-0.946405</td>\n      <td>0.008669</td>\n      <td>0.033927</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>u</td>\n      <td>5.590170</td>\n      <td>7.0</td>\n      <td>0</td>\n      <td>0.189590</td>\n      <td>0.171600</td>\n      <td>-0.762683</td>\n      <td>-0.944200</td>\n      <td>0.187224</td>\n      <td>0.202541</td>\n      <td>...</td>\n      <td>-0.728503</td>\n      <td>-0.938528</td>\n      <td>-0.168419</td>\n      <td>-0.152817</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>v</td>\n      <td>3.640055</td>\n      <td>5.0</td>\n      <td>2</td>\n      <td>-0.026683</td>\n      <td>-0.029301</td>\n      <td>-0.804434</td>\n      <td>-0.964422</td>\n      <td>-0.034225</td>\n      <td>0.001689</td>\n      <td>...</td>\n      <td>-0.794487</td>\n      <td>-0.961904</td>\n      <td>0.030610</td>\n      <td>0.063340</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>w</td>\n      <td>1.118034</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>-0.290480</td>\n      <td>-0.277180</td>\n      <td>-0.811823</td>\n      <td>-0.964282</td>\n      <td>-0.290284</td>\n      <td>-0.248117</td>\n      <td>...</td>\n      <td>-0.689123</td>\n      <td>-0.922525</td>\n      <td>0.275227</td>\n      <td>0.301285</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>x</td>\n      <td>1.802776</td>\n      <td>3.0</td>\n      <td>2</td>\n      <td>-0.161558</td>\n      <td>-0.153478</td>\n      <td>-0.790553</td>\n      <td>-0.957638</td>\n      <td>-0.158937</td>\n      <td>-0.130475</td>\n      <td>...</td>\n      <td>-0.721780</td>\n      <td>-0.938717</td>\n      <td>0.149529</td>\n      <td>0.175831</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>y</td>\n      <td>4.609772</td>\n      <td>6.0</td>\n      <td>0</td>\n      <td>0.108119</td>\n      <td>0.095498</td>\n      <td>-0.829017</td>\n      <td>-0.967917</td>\n      <td>0.091622</td>\n      <td>0.137070</td>\n      <td>...</td>\n      <td>-0.788343</td>\n      <td>-0.958688</td>\n      <td>-0.103080</td>\n      <td>-0.075300</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>z</td>\n      <td>1.118034</td>\n      <td>2.0</td>\n      <td>2</td>\n      <td>-0.318231</td>\n      <td>-0.302339</td>\n      <td>-0.740874</td>\n      <td>-0.939725</td>\n      <td>-0.302288</td>\n      <td>-0.293202</td>\n      <td>...</td>\n      <td>-0.642970</td>\n      <td>-0.898474</td>\n      <td>0.307220</td>\n      <td>0.326634</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>3.0</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>3.5</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>4.0</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>4.5</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>5.5</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>6.0</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>6.5</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td></td>\n      <td>4.031129</td>\n      <td>7.0</td>\n      <td>3</td>\n      <td>-0.159617</td>\n      <td>-0.154432</td>\n      <td>-0.821499</td>\n      <td>-0.968070</td>\n      <td>-0.166154</td>\n      <td>-0.121125</td>\n      <td>...</td>\n      <td>-0.800410</td>\n      <td>-0.964268</td>\n      <td>0.145335</td>\n      <td>0.183078</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>35 rows × 280 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PREPARE A DATAFRAME FOR HEATMAPS: MULTIPLY SPACES TO SHOW MULTIPLE BLOCKS\n",
    "\n",
    "df_heat = df_mean.copy()\n",
    "\n",
    "# Duplicate spaces\n",
    "space_x = df_heat['x'][0]\n",
    "row = df_heat.iloc[[0],]\n",
    "SPACEBAR_LEN = 9\n",
    "BLOCK_SIZE = 0.5\n",
    "for i in range(SPACEBAR_LEN):\n",
    "    new_block = space_x - (SPACEBAR_LEN - 1) / 2 * BLOCK_SIZE + i * BLOCK_SIZE\n",
    "    print(space_x, new_block)\n",
    "    if new_block == space_x:\n",
    "        continue\n",
    "\n",
    "    # append the other rows for spacebar draw\n",
    "    df_heat = df_heat.append(df_heat.loc[[0] * 1].assign(**{'x': new_block}), ignore_index=True) # 1 is the number of repeats\n",
    "\n",
    "df_heat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:title={'center':'Title'}, xlabel='x', ylabel='y'>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 720x216 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#HEATMAP - INTERACTIVE\n",
    "\n",
    "labz = [\n",
    "    ['q','','w','','e','','r','','t','','y','','u','','i','','o','','p'],\n",
    "    ['','a','','s','','d','','f','','g','','h','','j','','k','','l',''],\n",
    "    ['','','z','','x','','c','','v','','b','','n','','m','','','',''],\n",
    "    ['','','','','','','','','space','','','','','','','','','','']\n",
    "]\n",
    "\n",
    "# in pivot: 'y' is the index of rows, 'x' index of columns and 'dist' the value\n",
    "_ = df_heat.pivot('y', 'x', 'dist') # <--- Change here 'dist' to the column you want\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.axis('off')\n",
    "plt.title(\"Title\")\n",
    "sns.heatmap(_, annot=labz, fmt='', square=True, cbar_kws = dict(use_gridspec=False,location=\"bottom\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "#HEATMAP - GEN FILES\n",
    "\n",
    "take_out = ['x', 'y', 'dist', 'View']\n",
    "\n",
    "for col in df_heat.columns:\n",
    "    if col in take_out:\n",
    "        continue\n",
    "    _ = df_heat.pivot('y', 'x', col) # col takes all values of letters\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Heatmap: \" + col)\n",
    "    sns.heatmap(_, annot=labz, fmt='', square=True, cbar_kws = dict(use_gridspec=False,location=\"bottom\"))\n",
    "    plt.savefig(\"C:\\\\Users\\\\giuli\\\\Desktop\\\\imageLeft\\\\heatmap\\\\\" + col + \"_heat.png\", bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# compare machine learning algorithms\n",
    "\n",
    "models = []\n",
    "models.append(('RFC', \"RandomForestClassifier\", RandomForestClassifier(n_estimators = 100, random_state = 42)))\n",
    "models.append(('NB', \"GaussianNB\", GaussianNB()))\n",
    "models.append(('SVM', \"SVC\", SVC(C=1.0, kernel='linear', gamma='auto', random_state=42)))\n",
    "models.append(('CART', \"DecisionTreeClassifier\", DecisionTreeClassifier(random_state=42)))\n",
    "models.append(('ADA', \"AdaBoostClassifier\", AdaBoostClassifier(n_estimators=500, learning_rate=0.1)))\n",
    "models.append(('LR', \"LogisticRegression\", LogisticRegression(solver='liblinear', random_state = 42)))\n",
    "models.append(('KNN', \"KNeighborsClassifier\", KNeighborsClassifier(weights='distance', n_neighbors=30, n_jobs=-1)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16762, 276) (16762,)\n",
      "Train: 11733 11733 Test: 5029 5029\n",
      "{' ': 812, 'a': 312, 'b': 70, 'c': 137, 'd': 137, 'e': 503, 'f': 89, 'g': 82, 'h': 151, 'i': 362, 'j': 69, 'k': 67, 'l': 149, 'm': 96, 'n': 238, 'o': 284, 'p': 123, 'q': 61, 'r': 198, 's': 219, 't': 290, 'u': 177, 'v': 70, 'w': 81, 'x': 65, 'y': 104, 'z': 83}\n",
      "RFC: 39.430000\n",
      "NB: 26.650000\n",
      "SVM: 41.360000\n",
      "CART: 25.670000\n",
      "ADA: 18.450000\n",
      "LR: 40.370000\n",
      "KNN: 37.070000\n"
     ]
    }
   ],
   "source": [
    "features = df.drop(['View','User','Hand', 'Smartphone', 'x', 'y','dist'], axis=1)\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "labels = np.array(df['View'])\n",
    "features = np.array(features)\n",
    "\n",
    "# print(features)\n",
    "# print(labels)\n",
    "\n",
    "print(features.shape, labels.shape)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=0)\n",
    "for train_index, test_index in sss.split(features, labels):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "\n",
    "print(\"Train:\", len(X_train), len(y_train), \"Test:\", len(X_test), len(y_test))\n",
    "\n",
    "# print number of occurrences for each letters\n",
    "a, b = np.unique(y_test, return_counts=True)\n",
    "print(dict(zip(a, b)))\n",
    "\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "hue = []\n",
    "predictions = []\n",
    "\n",
    "y_pred_result = []\n",
    "\n",
    "for name, full_name, model in models:\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = round(metrics.accuracy_score(y_test, y_pred) * 100, 2)\n",
    "\n",
    "    y_pred_result.append(y_pred)\n",
    "    predictions.append((full_name, y_pred))\n",
    "    results.append(accuracy)\n",
    "    names.append(name)\n",
    "    hue.append(full_name + \": \" + str(accuracy) + \"%\")\n",
    "\n",
    "    print('%s: %f' % (name, accuracy))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# plot ACCURACY of ML Algorithm\n",
    "\n",
    "graphData = pd.DataFrame({'names':names,'results':results, 'algorithm':hue})\n",
    "fig = pyplot.figure(figsize=(24,14), dpi=100)\n",
    "pyplot.title('Accuracy', fontweight='bold')\n",
    "plt_bar = sns.barplot(x='names', y='results', data=graphData, hue='algorithm', dodge=False)\n",
    "pyplot.xlabel(\"algorithm\", fontweight='bold')\n",
    "pyplot.ylabel(\"accuracy\", fontweight='bold')\n",
    "plt.yticks(np.arange(0, 105, 5), fontsize=15)\n",
    "plt.xticks(fontsize=17)\n",
    "plt.setp(plt_bar.get_legend().get_texts(), fontsize='15') # for legend text\n",
    "plt.setp(plt_bar.get_legend().get_title(), fontsize='16', fontweight='bold') # for legend title\n",
    "pyplot.savefig(\"C:\\\\Users\\\\giuli\\\\Desktop\\\\imageLeft\\\\\" + \"accuracyLeft.png\",\n",
    "               bbox_inches='tight')\n",
    "# pyplot.show()\n",
    "pyplot.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# mod = AdaBoostClassifier()\n",
    "# # define the grid of values to search\n",
    "# grid = dict()\n",
    "# grid['n_estimators'] = [10, 50, 100, 500]\n",
    "# grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "# grid['algorithm'] = ['SAMME', 'SAMME.R']\n",
    "# # define the evaluation procedure\n",
    "# # define the grid search procedure\n",
    "# grid_search = GridSearchCV(estimator=mod, param_grid=grid, n_jobs=-1, cv=sss, scoring='accuracy')\n",
    "# # execute the grid search\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# # summarize the best score and configuration\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# mod = SVC(probability=True, shrinking=False, gamma='auto', decision_function_shape='ovo', C=1.0, kernel='linear', random_state=42)\n",
    "# # define the grid of values to search\n",
    "# grid = dict()\n",
    "# # grid['C'] = [0.001, 0.01, 0.1, 1.0]\n",
    "# # grid['kernel'] = ['linear', 'rbf', 'sigmoid', 'poly']\n",
    "# # grid['degree'] = [3, 4, 5]\n",
    "# # grid['gamma'] = ['auto', 'scale']\n",
    "# # grid['shrinking'] = [True, False]\n",
    "# # grid['probability'] = [True, False]\n",
    "# # grid['decision_function_shape'] = ['ovo', 'ovr']\n",
    "# grid['break_ties'] = [True, False]\n",
    "# # define the evaluation procedure\n",
    "# # define the grid search procedure\n",
    "# grid_search = GridSearchCV(estimator=mod, param_grid=grid, n_jobs=-1, cv=sss, scoring='accuracy')\n",
    "# # execute the grid search\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# # summarize the best score and configuration\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# mod = LogisticRegression(random_state=42, multi_class='auto')\n",
    "# # define the grid of values to search\n",
    "# grid = dict()\n",
    "# grid['C'] = [0.001, 0.01, 0.1, 1.0]\n",
    "# grid['solver'] = ['linear', 'newton-cg', 'lbfgs', 'saga']\n",
    "# # define the evaluation procedure\n",
    "# # define the grid search procedure\n",
    "# grid_search = GridSearchCV(estimator=mod, param_grid=grid, n_jobs=-1, cv=sss, scoring='accuracy')\n",
    "# # execute the grid search\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# # summarize the best score and configuration\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# mod = DecisionTreeClassifier(random_state=42)\n",
    "# # define the grid of values to search\n",
    "# grid = dict()\n",
    "# grid['splitter'] = ['best', 'random']\n",
    "# grid['max_features'] = ['auto', 'sqrt', 'log2', None]\n",
    "# # define the evaluation procedure\n",
    "# # define the grid search procedure\n",
    "# grid_search = GridSearchCV(estimator=mod, param_grid=grid, n_jobs=-1, cv=sss, scoring='accuracy')\n",
    "# # execute the grid search\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# # summarize the best score and configuration\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# mod = KNeighborsClassifier(n_jobs=-1)\n",
    "# # define the grid of values to search\n",
    "# grid = dict()\n",
    "# grid['n_neighbors'] = [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
    "#                        21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "# grid['weights'] = ['uniform', 'distance']\n",
    "# grid['algorithm'] = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "# # define the evaluation procedure\n",
    "# # define the grid search procedure\n",
    "# grid_search = GridSearchCV(estimator=mod, param_grid=grid, n_jobs=-1, cv=sss, scoring='accuracy')\n",
    "# # execute the grid search\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# # summarize the best score and configuration\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1728x1008 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mod = RandomForestClassifier(random_state=42)\n",
    "# # define the grid of values to search\n",
    "# grid = dict()\n",
    "# grid['n_estimators'] = [10, 50, 100, 500]\n",
    "# grid['min_samples_leaf'] = [1, 75]\n",
    "# # define the evaluation procedure\n",
    "# # define the grid search procedure\n",
    "# grid_search = GridSearchCV(estimator=mod, param_grid=grid, n_jobs=-1, cv=sss, scoring='accuracy')\n",
    "# # execute the grid search\n",
    "# grid_result = grid_search.fit(X_train, y_train)\n",
    "# # summarize the best score and configuration\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, f1_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "\n",
    "idx = [17, 23, 1, 5, 19, 26, 18, 4, 24, 20, 6, 3, 25, 7, 22, 0, 21, 8, 2, 9, 10, 14, 15, 11, 13, 16, 12]\n",
    "\n",
    "labels_order = a[idx]\n",
    "\n",
    "ticklabels = [i for i in \"QWAESZRDXTFCYGV UHBIJNOKMPL\"]\n",
    "zip_labels = list(zip(idx, ticklabels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "GaussianNB\n",
      "SVC\n",
      "DecisionTreeClassifier\n",
      "AdaBoostClassifier\n",
      "LogisticRegression\n",
      "KNeighborsClassifier\n"
     ]
    }
   ],
   "source": [
    "# plot CONFUSION MATRIX not scaled\n",
    "\n",
    "copy_conf = []\n",
    "\n",
    "for name, prediction in predictions:\n",
    "\n",
    "    c, d = np.unique(prediction, return_counts=True)\n",
    "    # print(dict(zip(c, d)))\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, prediction, labels=labels_order)\n",
    "\n",
    "    copy_conf.append((name, conf_matrix))\n",
    "\n",
    "    print(name)\n",
    "\n",
    "    # number of letters for each rows\n",
    "    # print(name, list(map(sum, conf_matrix)))\n",
    "\n",
    "    # number of letters for each columns\n",
    "    # print(name, [sum(conf_matrix[:,i]) for i in range(27)])\n",
    "\n",
    "    df_cm = pd.DataFrame(conf_matrix, index = idx, columns = idx)\n",
    "\n",
    "    plt.figure(figsize = (24,14), dpi=100)\n",
    "    sns.set(font_scale=1)\n",
    "\n",
    "    sns.heatmap(df_cm, annot=True, yticklabels=zip_labels, xticklabels=ticklabels, annot_kws={\"fontsize\":10})\n",
    "\n",
    "    plt.title(\"confusion_matrix: \" + name, fontweight='bold')\n",
    "    plt.ylabel(\"actual\", fontweight='bold')\n",
    "    plt.xlabel(\"predicted\", fontweight='bold')\n",
    "\n",
    "    plt.savefig(\"C:\\\\Users\\\\giuli\\\\Desktop\\\\imageLeft\\\\confusion_matrix\\\\non scalati\\\\\" + name +\n",
    "                \"_confusion_matrix.png\", bbox_inches='tight')\n",
    "\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# plot CONFUSION MATRIX scaled\n",
    "\n",
    "copy_conf_scaled = []\n",
    "\n",
    "for name, prediction in predictions:\n",
    "\n",
    "    c, d = np.unique(prediction, return_counts=True)\n",
    "    # print(dict(zip(c, d)))\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, prediction, labels=labels_order)\n",
    "\n",
    "    conf_scaled = (conf_matrix.astype(float)/conf_matrix.astype(float).sum(axis=1)[:, np.newaxis]) * 100\n",
    "\n",
    "    copy_conf_scaled.append((name, conf_scaled))\n",
    "\n",
    "    # print(name, list(map(sum, conf_scaled)))\n",
    "\n",
    "    df_cm = pd.DataFrame(conf_scaled, index = idx, columns = idx)\n",
    "\n",
    "    plt.figure(figsize = (24,14), dpi=100)\n",
    "    sns.set(font_scale=1)\n",
    "\n",
    "    sns.heatmap(df_cm, annot=True, yticklabels=zip_labels, xticklabels=ticklabels, annot_kws={\"fontsize\":10})\n",
    "\n",
    "    plt.title(\"confusion_matrix: \" + name, fontweight='bold')\n",
    "    plt.ylabel(\"actual\", fontweight='bold')\n",
    "    plt.xlabel(\"predicted\", fontweight='bold')\n",
    "\n",
    "    plt.savefig(\"C:\\\\Users\\\\giuli\\\\Desktop\\\\imageLeft\\\\confusion_matrix\\\\scalati\\\\\" + name +\n",
    "                \"_confusion_matrix.png\", bbox_inches='tight')\n",
    "\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giuli\\AppData\\Local\\Temp/ipykernel_3936/1748257599.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  nArr2D = np.array(copy_conf)\n"
     ]
    }
   ],
   "source": [
    "# keyboard = [('q', 0), ('w', 1), ('a', 1), ('e', 2), ('s', 2), ('z', 2), ('r', 3), ('d', 3), ('x', 3), ('t', 4), ('f', 4),\n",
    "#             ('c', 4), ('y', 5), ('g', 5), ('v', 5), (' ', 5), ('u', 6), ('h', 6), ('b', 6), ('i', 7), ('j', 7), ('n', 7),\n",
    "#             ('o', 8), ('k', 8), ('m', 8), ('p', 9), ('l', 9)]\n",
    "\n",
    "# distances of each letter from the others\n",
    "\n",
    "nArr2D = np.array(copy_conf)\n",
    "keyboard_q = [0, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 4, 6, 6, 6, 7, 7, 7, 8, 8, 8, 9, 9]\n",
    "keyboard_w = [1, 0, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 3, 5, 5, 5, 6, 6, 6, 7, 7, 7, 8, 8]\n",
    "keyboard_a = [1, 1, 0, 2, 1, 1, 3, 2, 2, 4, 3, 3, 5, 4, 4, 3, 6, 5, 5, 7, 6, 6, 8, 7, 7, 9, 8]\n",
    "keyboard_e = [2, 1, 2, 0, 1, 2, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7]\n",
    "keyboard_s = [2, 1, 1, 1, 0, 1, 2, 1, 1, 3, 2, 2, 4, 3, 3, 2, 5, 4, 4, 6, 5, 5, 7, 6, 6, 8, 7]\n",
    "keyboard_z = [2, 2, 1, 2, 1, 0, 2, 1, 1, 3, 2, 2, 4, 3, 3, 2, 5, 4, 4, 6, 5, 5, 7, 6, 6, 8, 7]\n",
    "keyboard_r = [3, 2, 3, 1, 2, 2, 0, 1, 2, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6]\n",
    "keyboard_d = [3, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 3, 2, 2, 2, 4, 3, 3, 5, 4, 4, 6, 5, 5, 7, 6]\n",
    "keyboard_x = [3, 2, 2, 2, 1, 1, 2, 1, 0, 2, 1, 1, 3, 2, 2, 1, 4, 3, 3, 5, 4, 4, 6, 5, 5, 7, 6]\n",
    "keyboard_t = [4, 3, 4, 2, 3, 3, 1, 2, 2, 0, 1, 2, 1, 1, 2, 3, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5]\n",
    "keyboard_f = [4, 3, 3, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 2, 3, 2, 2, 4, 3, 3, 5, 4, 4, 6, 5]\n",
    "keyboard_c = [4, 3, 3, 2, 2, 2, 2, 1, 1, 2, 1, 0, 2, 1, 1, 1, 3, 2, 2, 4, 3, 3, 5, 4, 4, 6, 5]\n",
    "keyboard_y = [5, 4, 5, 3, 4, 4, 2, 3, 3, 1, 2, 2, 0, 1, 2, 3, 1, 1, 2, 2, 2, 2, 3, 3, 3, 4, 4]\n",
    "keyboard_g = [5, 4, 4, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 2, 1, 1, 3, 2, 2, 4, 3, 3, 5, 4]\n",
    "keyboard_v = [5, 4, 4, 3, 3, 3, 2, 2, 2, 2, 1, 1, 2, 1, 0, 1, 2, 1, 1, 3, 2, 2, 4, 3, 3, 5, 4]\n",
    "keyboard_  = [4, 3, 3, 3, 2, 2, 3, 2, 1, 3, 2, 1, 3, 2, 1, 0, 3, 2, 1, 3, 2, 1, 3, 2, 2, 4, 3]\n",
    "keyboard_u = [6, 5, 6, 4, 5, 5, 3, 4, 4, 2, 3, 3, 1, 2, 2, 3, 0, 1, 2, 1, 1, 2, 2, 2, 2, 3, 3]\n",
    "keyboard_h = [6, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 1, 1, 1, 2, 1, 0, 1, 2, 1, 1, 3, 2, 2, 4, 3]\n",
    "keyboard_b = [6, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 2, 1, 0, 2, 1, 1, 3, 2, 2, 4, 3]\n",
    "keyboard_i = [7, 6, 7, 5, 6, 6, 4, 5, 5, 3, 4, 4, 2, 3, 3, 3, 1, 2, 2, 0, 1, 2, 1, 1, 2, 2, 2]\n",
    "keyboard_j = [7, 6, 6, 5, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1, 1, 3, 2]\n",
    "keyboard_n = [7, 6, 6, 5, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 1, 2, 1, 1, 2, 1, 0, 2, 1, 1, 3, 2]\n",
    "keyboard_o = [8, 7, 8, 6, 7, 7, 5, 6, 6, 4, 5, 5, 3, 4, 4, 3, 2, 3, 3, 1, 2, 2, 0, 1, 2, 1, 1]\n",
    "keyboard_k = [8, 7, 7, 6, 6, 6, 5, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 2, 1]\n",
    "keyboard_m = [8, 7, 7, 6, 6, 6, 5, 5, 5, 4, 4, 4, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 2, 1, 0, 2, 1]\n",
    "keyboard_p = [9, 8, 9, 7, 8, 8, 6, 7, 7, 5, 6, 6, 4, 5, 5, 4, 3, 4, 4, 2, 3, 3, 1, 2, 2, 0, 1]\n",
    "keyboard_l = [9, 8, 8, 7, 7, 7, 6, 6, 6, 5, 5, 5, 4, 4, 4, 3, 3, 3, 3, 2, 2, 2, 1, 1, 1, 1, 0]\n",
    "\n",
    "\n",
    "keyboard = [keyboard_q, keyboard_w, keyboard_a, keyboard_e, keyboard_s, keyboard_z, keyboard_r, keyboard_d, keyboard_x,\n",
    "            keyboard_t, keyboard_f, keyboard_c, keyboard_y, keyboard_g, keyboard_v, keyboard_, keyboard_u, keyboard_h,\n",
    "            keyboard_b, keyboard_i, keyboard_j, keyboard_n, keyboard_o, keyboard_k, keyboard_m, keyboard_p, keyboard_l]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# create new matrix with distance\n",
    "\n",
    "def matrix_distance(m_distance):\n",
    "    actual = 0\n",
    "    row_conf = 0\n",
    "    new_matrix = []\n",
    "    matrix_to_return = []\n",
    "    indexes = []\n",
    "    summ = []\n",
    "\n",
    "    for name, c_matrix in m_distance:\n",
    "        for keyb in keyboard:\n",
    "            for i in range(0, max(keyb)+1):\n",
    "                for j in keyb:\n",
    "                    if i == j:\n",
    "                        indexes.append(actual)\n",
    "                    actual += 1\n",
    "\n",
    "                # print(indexes)\n",
    "                sum_values = sum(c_matrix[row_conf][indexes])\n",
    "                summ.append(sum_values)\n",
    "                indexes = []\n",
    "                actual = 0\n",
    "            row_conf += 1\n",
    "\n",
    "            new_matrix.append(summ)\n",
    "            summ = []\n",
    "\n",
    "        matrix_to_return.append((name, new_matrix))\n",
    "        new_matrix = []\n",
    "        row_conf = 0\n",
    "\n",
    "    return matrix_to_return\n",
    "\n",
    "\n",
    "# print(matrix_distance(copy_conf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# create plot of matrix with distance\n",
    "\n",
    "def create_plot_distance(copy_matrix, path_file):\n",
    "\n",
    "    for name_alg, matrix in matrix_distance(copy_matrix):\n",
    "\n",
    "        conf_matrix_distance = pd.DataFrame(matrix, index = idx, columns = range(0, 10))\n",
    "\n",
    "        plt.figure(figsize = (24,14), dpi=100)\n",
    "        sns.set(font_scale=1)\n",
    "\n",
    "        sns.heatmap(conf_matrix_distance, annot=True, yticklabels=zip_labels, xticklabels=range(0, 10), annot_kws={\"fontsize\":10}, fmt='.0f')\n",
    "\n",
    "        plt.title(name_alg + \"_distance\", fontweight='bold')\n",
    "        plt.ylabel(\"actual\", fontweight='bold')\n",
    "        plt.xlabel(\"distance\", fontweight='bold')\n",
    "\n",
    "        plt.savefig(\"C:\\\\Users\\\\giuli\\\\Desktop\\\\imageLeft\\\\confusion_matrix\\\\\" + path_file + \"\\\\\" + name_alg +\n",
    "                        \"_distance.png\", bbox_inches='tight')\n",
    "\n",
    "        plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "create_plot_distance(copy_conf, \"distanze non scalate\")\n",
    "create_plot_distance(copy_conf_scaled, \"distanze scalate\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "SVC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "KNeighborsClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\users\\giuli\\desktop\\pythontesi\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# plot F1-SCORE, PRECISION and RECALL\n",
    "\n",
    "alphabet = [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p',\n",
    "            'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# set width of bars\n",
    "bar_width = 0.25\n",
    "\n",
    "for name, prediction in predictions:\n",
    "    print(name)\n",
    "    report = classification_report(y_test, prediction, output_dict=True)\n",
    "    data_report = pd.DataFrame(report).transpose()\n",
    "    precision = round(data_report.loc[:, 'precision'], 2)\n",
    "    recall = round(data_report.loc[:, 'recall'], 2)\n",
    "    f_score = round(data_report.loc[:, 'f1-score'], 2)\n",
    "    prec = precision.head(27)\n",
    "    rec = recall.head(27)\n",
    "    f = f_score.head(27)\n",
    "\n",
    "    # print(name, f1_score(y_test, prediction, average=None))\n",
    "\n",
    "    # Set position of bar on X axis\n",
    "    r1 = np.arange(27)\n",
    "    r2 = [xindex + bar_width for xindex in r1]\n",
    "    r3 = [xindex + bar_width for xindex in r2]\n",
    "\n",
    "    # Make the plot\n",
    "    plt.figure(figsize = (24,14), dpi=100)\n",
    "    plt.bar(r1, prec, width=bar_width, edgecolor='white', label='precision')\n",
    "    plt.bar(r2, rec, width=bar_width, edgecolor='white', label='recall')\n",
    "    plt.bar(r3, f, width=bar_width, edgecolor='white', label='f1-score')\n",
    "\n",
    "    # Add xticks and yticks on the middle of the group bars\n",
    "    # plt.xlabel('labels', fontweight='bold')\n",
    "    plt.title(\"Precision, Recall, F1 Score: \" + name, fontweight='bold')\n",
    "    plt.yticks(np.arange(0, 1.05, 0.05), fontsize=15)\n",
    "    plt.xticks([r + bar_width for r in range(27)], alphabet, fontsize=20)\n",
    "\n",
    "    # create legend, save graphic\n",
    "    plt.legend(prop={\"size\":20})\n",
    "\n",
    "    plt.savefig(\"C:\\\\Users\\\\giuli\\\\Desktop\\\\imageLeft\\\\f_score\\\\\" + name + \"_f_score.png\",\n",
    "                bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}